# ğŸ’¬ Hi_LLM_Chat: Your Local Multi-Turn Chatbot Powered by Llama 3.2 1B

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)

**Hi_LLM_Chat** is a simple yet powerful multi-turn chatbot that runs entirely on your local machine. It's built upon the **Llama 3.2 1B model** and aims for natural conversations with users. Experience real-time interaction with its **streaming text generation** feature! ğŸš€

## âœ¨ Key Features

* **ğŸ–¥ï¸ 100% Local Execution:** No internet connection or external API calls needed (after model download). Everything is processed on your PC.
* **ğŸ”„ Multi-Turn Conversation Support:** Remembers previous parts of the conversation for contextual responses.
* **ğŸ¦™ Utilizes Llama 3.2 1B Model:** Leverages a capable yet relatively lightweight large language model.
* **ğŸ’¨ Real-time Streaming Output:** Responses appear token-by-token, like someone typing in real-time, making interactions more engaging.
* **ğŸ”§ Simple Structure:** Focuses on core chatbot functionality, making it easy to understand and modify.

## ğŸ¬ Demo (Optional)

*(Consider embedding or linking to a demo video showcasing the chatbot in action here.)*

## âš™ï¸ Requirements

* **Python:** 3.8+ recommended
* **Llama 3.2 1B Model Weights & Tokenizer:** You need the official Llama 3.2 1B model weights and associated tokenizer files. Request access and download them from Meta's official channels: [https://llama.meta.com/llama-downloads/](https://llama.meta.com/llama-downloads/) (Follow the instructions on the site).

## ğŸ› ï¸ Setup

1.  **Clone the Repository:**
    ```bash
    git clone https://github.com/bok3948/Hi_LLM_Chat.git
    cd Hi_LLM_Chat
    ```

2.  **Download Model & Tokenizer:**
    * Obtain the Llama 3.2 1B (Instruct version recommended for chat) model weights and tokenizer from the official Meta channels (see Requirements).
    * Create a directory within the project to store the model files (e.g., `./llama3.2-1B-instruct/`).
    * Place all the downloaded model files (e.g., `consolidated.00.pth` or `.safetensors` files, `tokenizer.model`, `params.json`, or the relevant `.gguf` file if using llama.cpp) into the directory you created.
    * **Important:** You might need to update the model path in the configuration file or script (`config.py`, `chat.py`, etc.) to point to this directory.
    * ì•„, ì£„ì†¡í•©ë‹ˆë‹¤! ì œê°€ "ë„ì‹"ì´ë¼ëŠ” ì˜ë¯¸ë¥¼ ì˜ëª» ì´í•´í–ˆë„¤ìš”. ì„¤ì • ê³¼ì •ì˜ íë¦„ë„ê°€ ì•„ë‹ˆë¼, ì„¤ì •ì„ ì™„ë£Œí–ˆì„ ë•Œ ì˜ˆìƒë˜ëŠ” í”„ë¡œì íŠ¸ í´ë”ì˜ êµ¬ì¡°ë¥¼ ë³´ì—¬ë‹¬ë¼ëŠ” ì˜ë¯¸ì…¨êµ°ìš”.

README.mdì— í¬í•¨í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ, ì™„ì„±ëœ í´ë” êµ¬ì¡° ì˜ˆì‹œë¥¼ í…ìŠ¤íŠ¸ë¡œ í‘œí˜„í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

Markdown

## ğŸ“‚ Expected Directory Structure

After completing the setup steps (cloning the repository, downloading the model, and placing the files), your project directory should look something like this:

    Hi_LLM_Chat/
    â”‚
    â”œâ”€â”€ llama3.2-1B-instruct/     <-- Directory for model files (Created in Setup Step 2)
    â”‚   â”‚
    â”‚   â”œâ”€â”€ consolidated.00.pth   <-- Example Llama 3.2 weight file(s)
    â”‚   â”œâ”€â”€ (or *.safetensors)    <-- Alternative weight file format
    â”‚   â”œâ”€â”€ (or *.gguf)           <-- Example GGUF model file (if using llama.cpp)
    â”‚   â”‚
    â”‚   â”œâ”€â”€ tokenizer.model       <-- Llama 3.2 tokenizer file
    â”‚   â”œâ”€â”€ params.json           <-- Model parameters file
    â”‚   â””â”€â”€ ...                   <-- Any other files included with the download
    â”‚
    â”œâ”€â”€ chat.py                   <-- Your main chatbot script (Example name)
    â”œâ”€â”€ requirements.txt          <-- List of required Python libraries
    â”œâ”€â”€ config.py                 <-- Optional configuration file (Example name)
    â”œâ”€â”€ README.md                 <-- This README file

3.  **Install Required Libraries:**
    ```bash
    pip install -r requirements.txt # Ensure you have this requirements.txt file
    ```
    * Note: If you need GPU support (e.g., for `llama-cpp-python`), refer to the specific library's documentation for installation options.

## â–¶ï¸ Usage

**Run the Chatbot:** Open your terminal and execute the main script:
```bash
python chat.py # Or the actual name of your execution script
```


---
